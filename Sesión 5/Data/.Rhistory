1
visit.df$Goles.V[1];
as.integer(visit.df$Goles.V[1]);
visit.df$Goles.V[1];
as.integer(5); # visit.df$Goles.V[1];
as.integer('5'); # visit.df$Goles.V[1];
visit.df$Goles.V[1];
visit.df$Goles.V[4];
# Probabilidad conjunta de que el equipo en casa anote x goles
# y el equipo que juega como visitante anote y goles
x.size <- length(local.df$Goles.L);
y.size <- length(visit.df$Goles.V);
goles.x <- vector('integer', 0);
goles.y <- vector('integer', 0);
prob.x <- vector('numeric', 0);
prob.y <- vector('numeric', 0);
prob.x.y <- vector('numeric', 0);
i <- 1;
while(i <= x.size) {
j <- 1;
while(j <= y.size) {
goles.x <- append(goles.x, as.integer(local.df$Goles.L[i]) - 1);
goles.y <- append(goles.y, as.integer(visit.df$Goles.V[j]) - 1);
prob.x <- append(prob.x, local.df$Probabilidad[i]);
prob.y <- append(prob.y, visit.df$Probabilidad[j]);
probConjunta <-
round((local.df$Probabilidad[i] * visit.df$Probabilidad[j]) / 100, 2);
prob.x.y <- append(prob.x.y, probConjunta);
j <- j + 1;
}
i <- i + 1;
}
loc.visit.df <- data.frame('Goles.L' = goles.x,
'Goles.V' = goles.y,
'Prob.L' = prob.x,
'Prob.V' = prob.y,
'Prob.L.V' = prob.x.y);
loc.visit.df;
(loc.visit.df <- data.frame('Goles.L' = goles.x,
'Goles.V' = goles.y,
'Prob.L' = prob.x,
'Prob.V' = prob.y,
'Prob.L.V' = prob.x.y));
(loc.visit.df <- data.frame('Goles.L' = goles.x,
'Goles.V' = goles.y,
'Prob.L' = prob.x,
'Prob.V' = prob.y,
'Prob.L.V' = prob.x.y));
# Ejemplo 1: Medidas de tendencia central, de posición y de dispersión
# ---------------------
# Media
x = c(4000, 9000, 9000, 10000);
mean(x);
# Mediana
median(x);
# Ejemplo 1: Medidas de tendencia central, de posición y de dispersión
# ---------------------
# Media
x = c(4000, 9000, 9500, 10000);
# Mediana
median(x);
# Ejemplo 1: Medidas de tendencia central, de posición y de dispersión
# ---------------------
# Media
x = c(4000, 9000, 9100, 10000);
# Mediana
median(x);
# Ejemplo 1: Medidas de tendencia central, de posición y de dispersión
# ---------------------
# Media
x = c(4000, 9000, 9000, 10000);
install.packages("DescTools")
# Moda con paquete DescTools
library('DescTools');
Mode(x);
x
Mode(x);
# Medidas de posición
x <- c(29, 13, 62, 4, 63, 96, 1, 90, 50, 46);
quantile(x, 0.25);
qunatile(x, c(0.25, 0.50, 0.75));
qunatile(x, c(0.25, 0.50, 0.75));
quantile(x, c(0.25, 0.50, 0.75));
quantile(x, seq(0.1,0.9, by=0.1)); # Deciles
quantile(x, seq(0.1,0.9, by=0.1)); # Deciles
quantile(x, 0.25); # Cuantil 25%
quantile(x, c(0.25, 0.50, 0.75)); # Cuartiles
sort(x)
# Rango intercuantílico
IQR(x);
qunatile(x, 0.75) - qunatile(x, 0.25);
qunatile(x, 0.75) - qunatile(x, 0.25);
quantile(x, 0.75) - quantile(x, 0.25);
# Rango intercuantílico
IQR(x);
# Varianza
var(x);
?var
sd(x);
# Reto 1
# ---------------------
# Considere el vector
set.seed(134);
x <- round(rnorm(1000, 175, 6), 1);
x
# Calcule la media, mediana y moda
mean(x);
median(x);
library(DescTools);
Mode(x);
# Obtenga los deciles de x
quantile(x, seq(0.1, 0.9, by = 0.1));
# Encuentre el rango intercuartílico, desviación estándar y varianza muestral
IQR(x);
quantile(x, 0.75) - quantile(x, 0.25);
sd(x);
var(x);
pnorm(q = 18, mean = 16, sd = 1, lower.tail = F);
# Área correspondiente a dicha probabilidad (intervalo)
plot(x, y, type = "l");
title(main = "Densidad de Probabilidad de Botellas",
sub = expression(paste(mu == 16, " y ", sigma == 1)));
polygon(c(18, x[x>=18], max(x)), c(0, y[x>=18], 0), col = "green");
# P(X>=18)
pnorm(q = 18, mean = 16, sd = 1, lower.tail = F);
# Valorrs posibles de la v.a.
x <- seq(-4, 4, 0.01) + 16;
y <- dnorm(x, mean = 16, sd = 1);
plot(x, y, type = "l");
title(main = "Densidad de Probabilidad de Botellas",
sub = expression(paste(mu == 16, " y ", sigma == 1)));
polygon(c(18, x[x>=18], max(x)), c(0, y[x>=18], 0), col = "green");
# Ejemplo 2. Teorema central del límite
# ----------------------------
# Cargar ggplot para graficar
library(ggplot2)
# Variable aleatoria (v.a.) X con distribución exponencial
# y parámetro lambda = 2
x <- seq(0, 5, 0.02);
x <- seq(0, 5, 0.02)
plot(x, dexp(x, rate = 2), type = "l", lwd = 2, ylab = "")
title(main = "Función de Densidad Exponencial", ylab = "f(x)",
sub = expression("Parámetro " ~ lambda == 2))
text(x = 3, y = 1.5, labels = expression(f(x)==2*exp(-2*x) ~ " para x "  >= 0))
text(x = 3, y = 1.3, labels = paste("0 en otro caso"))
text(x = 1, y = 1, labels = expression("E(X) = " ~ 1/lambda == 1/2), col = 2)
text(x = 3, y = 0.5, labels = expression("DE(X) = " ~ 1/lambda == 1/2), col = 4)
(m1.4 <- rexp(n = 4, rate = 2))
# Media de la muestra generada
mean(m1.4)
# Ahora obtener 5 muestras de tamaño 3
set.seed(64);
set.seed(64);
(m5.3 <- sapply(X = rep(3, 5), FUN = rexp, 2));
# Media de la muestra con n = 5
(media5.3 <- apply(m5.3, 2, mean));
# Variable aleatoria (v.a.) X con distribución exponencial
# y parámetro lambda = 2
x <- seq(0, 5, 0.02)
# Generar 1000 muestras de tamaño 7 y las 1000 medias correspondientes
set.seed(465);
m1000.7 <- apply(X = rep(7, 1000), FUN = rexp, 2);
m1000.7 <- Sapply(X = rep(7, 1000), FUN = rexp, 2);
m1000.7 <- sapply(X = rep(7, 1000), FUN = rexp, 2);
media1000.7 <- apply(m1000.7, 2, mean);
mdf <- as.data.frame(media1000.7);
tail(mdf)
# Ejemplo 2. Teorema central del límite
# ----------------------------
# Cargar ggplot para graficar
library(ggplot2)
# Histograma aproximado a forma de campana
ggplot(mdf, aes(media1000.7)) +
geom_histogram(colour = 'green',
fill = 'orange',
alpha = 0.7) + # Intensidad del color fill
geom_vline(xintercept = mean(media1000.7), linetype="dashed", color = "black") +
ggtitle('Histograma para las 1000 medias') +
labs(x = 'medias', y = 'Frecuencia')+
theme_bw() +
theme(plot.title = element_text(hjust = 0.5, size = 16))
set.seed(4465);
m1000.33 <- sapply(X = rep(33, 1000), FUN = rexp, 2);
media1000.33 <- apply(m1000.33, 2, mean);
mdf <- as.data.frame(media1000.33);
tail(mdf);
# Histograma aún más parecido a la campana
ggplot(mdf, aes(media1000.33)) +
geom_histogram(colour = 'yellow',
fill = 'purple',
alpha = 0.7) + # Intensidad del color fill
geom_vline(xintercept = mean(media1000.33), linetype="dashed", color = "black") +
ggtitle('Histograma para las 1000 medias') +
labs(x = 'medias', y = 'Frecuencia')+
theme_get() +
theme(plot.title = element_text(hjust = 0.5, size = 16))
# Reto 2. Teorema central del límite
# Las calificaciones de exámenes para todos los estudiantes
# de último año de preparatoria en cierto estado tienen media
# de 60 y varianza de 64. Una muestra aleatoria de n = 100
# estudiantes de una escuela preparatoria grande tuvo una
# calificación media de 58. ¿Hay evidencia para sugerir que
# el nivel de conocimientos de esta escuela sea inferior?
# (Calcule la probabilidad de que la media de una muestra
# aleatoria sea a lo sumo 58 cuando n = 100.)
pnorm(58, mean = 60, sd= 8/10)
?rexp
set.seed(174376);
m1 <- rexp(n = 56, rate = 4.1);
tail(as.data.frame(m1));
m2 <- rexp(n = 63, rate = 3.4);
tail(as.data.frame(m2));
set.seed(174376);
m1 <- rexp(n = 56, rate = 4.1);
tail(as.data.frame(m1));
m2 <- rexp(n = 63, rate = 3.4);
tail(as.data.frame(m2));
set.seed(174376);
n1 <- 56;
n2 <- 63;
m1 <- rexp(n = n1, rate = 4.1);
# media real = 1/4.1
m2 <- rexp(n = n2, rate = 3.4);
# media real = 1/3.4
# diferencia de medias real = 1/4.1 - 1/3.4
# Interesa encontrar la hipótesis H0:mu1-mu2=0 vs H1:mu1=mu2!=0
# (Contraste de dos colas)
# Valor observado del estadístico de prueba
z0 <- (mean(m1) - mean(m2)-0)/sqrt(var(m1)/n1 + var(m2)/n2);
z0
# Supongamos que estamos interesados en encontrar la región de rechazo
# con un nivel de significancia alpha = 0.05, se debe encontrar el valor
# z_{0.025} que satsiface P(Z > z_{0.025}) = 0.025
(z.025 <- qnorm(p = 0.025, lower.tail = FALSE));
# Puesto que
(z0 <- -z.025) | (z0 > z.025);
# el p-value se calcula como
(pvalue <- 2 * pnorm(z0, lower.tail = FALSE));
x <- seq(-4, 4, 0.01);
y <- dnorm(x);
plot(x, y, type = "l");
title(main = "Densidad normal estándar", sub = expression(paste(mu == 0, " y ", sigma == 1)));
polygon(c(min(x), x[x<=-z0], -z0), c(0, y[x<=-z0], 0), col = "purple");
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
# Supongamos que estamos interesados en encontrar la región de rechazo
# con un nivel de significancia alpha = 0.05, se debe encontrar el valor
# z_{0.025} que satsiface P(Z > z_{0.025}) = 0.025
(z.025 <- qnorm(p = 0.025, lower.tail = FALSE));
polygon(c(min(x), x[x<=-z0], -z0), c(0, y[x<=-z0], 0), col = "purple");
x <- seq(-4, 4, 0.01);
y <- dnorm(x);
plot(x, y, type = "l");
title(main = "Densidad normal estándar", sub = expression(paste(mu == 0, " y ", sigma == 1)));
polygon(c(min(x), x[x<=-z0], -z0), c(0, y[x<=-z0], 0), col = "purple");
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
plot(x, y, type = "l");
title(main = "Densidad normal estándar", sub = expression(paste(mu == 0, " y ", sigma == 1)));
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
axis(side = 1, at = -z0, font = 2, padj = 1, lwd = 2);
plot(x, y, type = "l");
title(main = "Densidad normal estándar", sub = expression(paste(mu == 0, " y ", sigma == 1)));
axis(side = 1, at = -z0, font = 2, padj = 1, lwd = 2);
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
polygon(c(z0, x[x>=z0], max(x)), c(0, y[x>=z0], 0), col = "purple");
polygon(c(min(x), x[x<=-z0], -z0), c(0, y[x<=-z0], 0), col = "purple");
z0
# Valor observado del estadístico de prueba
(z0 <- (mean(m1) - mean(m2) - 0)/sqrt(var(m1)/n1 + var(m2)/n2));
# Valor observado del estadístico de prueba
(z0 <- (mean(m1) - mean(m2)-0)/sqrt(var(m1)/n1 + var(m2)/n2));
# Valor observado del estadístico de prueba
(z0 <- (mean(m1) - mean(m2) - 0)/sqrt(var(m1)/n1 + var(m2)/n2));
polygon(c(min(x), x[x<=-z0], -z0), c(0, y[x<=-z0], 0), col = "purple");
dev.off()
plot(x, y, type = "l");
title(main = "Densidad normal estándar", sub = expression(paste(mu == 0, " y ", sigma == 1)));
polygon(c(min(x), x[x<=-z0], -z0), c(0, y[x<=-z0], 0), col = "purple");
axis(side = 1, at = -z0, font = 2, padj = 1, lwd = 2);
polygon(c(z0, x[x>=z0], max(x)), c(0, y[x>=z0], 0), col = "purple");
axis(side = 1, at = z0, font = 2, padj = 1, lwd = 2);
set.seed(1776);
n1 <- 23;
n2 <- 20
m1 <- rnorm(n = n1, mean = 175, sd = 3);
m2 <- rnorm(n = n2, mean = 160, sd = 3);
# diferencia de medias real
175 - 160;
# Valor observado del estadístico de prueba en este caso
(t0 <- (mean(m1)-mean(m2)-0)/(sqrt((22*var(m1)+19*var(m2))/(23+20-2))*sqrt(1/23+1/20)));
# Encontrar la región de rechazo (de dos colas) con un nivel de significancia
# alpha = 0.05, esto es, t_{0.025} tal que P(T > t_{0.025}) = 0.025
(t.025 <- qt(p = 0.025, df = 41, lower.tail = FALSE));
(t0 <- -t.025) | (t0 > t.025);
# p-value se puede calcular como
(pvalue <- 2*pt(t0, df = 41, lower.tail = FALSE));
# t.test sirve para realizar el procedimiento de contraste de hipótesis
t.test(x = m1, y = m2, alternative = "two.sided", mu = 0, paired = FALSE, var.equal = TRUE);
# Reto 3. Contraste de hipótesis
# El vicepresidente de ventas de una gran empresa afirma que los
# vendedores están promediando no más de 15 contactos de venta por
# semana. (Le gustaría aumentar esa cantidad.) Como prueba de su
# afirmación, aleatoriamente se seleccionan n = 20 vendedores y se
# registra el número de contactos hechos por cada uno para una sola
# semana seleccionada al azar.
muestra <- c(V1 = 13, V2 = 17, V3 = 20, V4 = 17, V5 = 20, V6 = 20,
V7 = 18, V8 = 18, V9 = 16, V10 = 19, V11 = 13,
V12 = 17, V13 = 15, V14 = 19, V15 = 16, V16 = 19,
V17 = 22, V18 = 10, V19 = 13, V20 = 21);
(t0 <- (mean(muestra) - 15)/(sd(muestra)/sqrt(20)));
(pvalue <- pt(t0, df = 19, lower.tail = FALSE));
t.test(x = muestra, alternative = "greater", mu = 15);
# Work 5
# Ejemplo 1. Regresión Lineal Múltiple
# -------------------------------
# Leer datos de restaurantes
setwd('C:/Users/abreg/Documents/DS-BEDU/Módulo 1/Sesión 5/Data');
# Work 5
# Ejemplo 1. Regresión Lineal Múltiple
# -------------------------------
# Leer datos de restaurantes
setwd('C:/Users/abreg/Documents/DS-BEDU/Módulo 1/Sesión 5/Data');
# Work 5
# Ejemplo 1. Regresión Lineal Múltiple
# -------------------------------
# Leer datos de restaurantes
setwd('C:/Users/abreg/Documents/DS-BEDU/Módulo 2/Sesión 5/Data');
nyc <- read.csv("nyc.csv", header = TRUE);
# Dimensión y atado de columnas
dim(nyc);
attach(nyc);
# Matriz de gráficos de dispersión
pairs(~ Price + Food + Decor + Service, data = nyc, gap = 0.4, cex.labels = 1.5)
# Ajuste de modelo
m1 <- lm(Price ~ Food + Decor + Service + East);
summary(m1);
# Modelo sin considerar service
m2 <- lm(Price ~ Food + Decor + East);
summary(m2);
# Análisis de covarianza
mfull <- lm(Price ~ Food + Decor + Service + East +
Food:East + Decor:East + Service:East);
summary(mfull);
# La prueba de si el efecto de los predictores depende de la variable
# dummy East puede lograrse usando la siguiente prueba-F parcial
anova(m2, mfull);
# Gráfica de Y, el precio contra los valores ajustados
plot(m2$fitted.values, Price, xlab = "Valores ajustados", ylab = "Price");
abline(lsfit(m2$fitted.values, Price));
# Matriz de gráficos de dispersión
pairs(~ Food + Decor, data = nyc, gap = 0.4, cex.labels = 1.5);
# Gráficas de residuales estandarizados
StanRes2 <- rstandard(m2);
par(mfrow = c(2, 2));
plot(Food, StanRes2, ylab = "Residuales Estandarizados");
plot(Decor, StanRes2, ylab = "Residuales Estandarizados");
plot(East, StanRes2, ylab = "Residuales Estandarizados");
dev.off()
# Evidencia para soportar la suposición de normalidad de los errores
qqnorm(StanRes2)
qqline(StanRes2)
# Ajuste modelos de regresión lineal múltiple a los datos
# advertisement.csv y elija el modelo "más adecuado" siguiendo
# los procedimientos vistos en el Ejemplo 1.
setwd('C:/Users/abre/documents/ds-bedu/modulo 2/sesión 5/data');
# Ajuste modelos de regresión lineal múltiple a los datos
# advertisement.csv y elija el modelo "más adecuado" siguiendo
# los procedimientos vistos en el Ejemplo 1.
setwd('C:/Users/abreg/documents/ds-bedu/modulo 2/sesión 5/data');
# Ajuste modelos de regresión lineal múltiple a los datos
# advertisement.csv y elija el modelo "más adecuado" siguiendo
# los procedimientos vistos en el Ejemplo 1.
setwd('C:/Users/abreg/documents/ds-bedu/módulo 2/sesión 5/data');
adv <- read.csv('advertising.csv');
attach(adv);
# Matriz de gráficos de dispersión
pairs(~ Sales + TV + Radio + Newspaper,
data = adv, gap = 0.4, cex.labels = 1.5);
# Ajuste de un modelo
# Sales = beta0 + beta1*TV + beta2*Radio + beta3*newspaper + e
m1 <- lm(Sales ~ Tv + Radio + Newspaper);
# Ajuste de un modelo
# Sales = beta0 + beta1*TV + beta2*Radio + beta3*newspaper + e
m1 <- lm(Sales ~ TV + Radio + Newspaper);
summary(m1);
# Se usará otro modelo sin newspaper pues el coeficiente de regresión
# no fue estadísticamente significativo (p-value)
# Sales = beta0 + beta1*TV + beta2*Radio + e
m2 <- update(m1, ~.-Newspaper);
summary(m2);
# Diagnósticos
plot(m2$fitted.values, Sales, xlab = "Valores ajustados", ylab = "Sales");
abline(lsfit(m2$fitted.values, Sales));
# Matriz de gráficos de dispersión de los dos predictores continuos
pairs(~ TV + Radio, data = adv, gap = 0.4, cex.labels = 1.5);
# Gráficas de residuales estandarizados contra predictor
StanRes2 <- rstandard(m2)
par(mfrow = c(2, 2))
plot(TV, StanRes2, ylab = "Residuales Estandarizados")
plot(Radio, StanRes2, ylab = "Residuales Estandarizados")
# Evidencia para soportar la hipótesis de normalidad de los errores
qqnorm(StanRes2)
qqline(StanRes2)
dev.off()
# Evidencia para soportar la hipótesis de normalidad de los errores
qqnorm(StanRes2)
qqline(StanRes2)
shapiro.test(StanRes2)
library(dplyr)
library(e1071)
library(ggplot2)
library(ISLR)
install.packages('ISLR')
# install.packages('ISLR')
library(ISLR)
?Default
head(Default)
tail(Default)
dim(Default)
str(Default)
# Gráfico de dispersión con la variable balance en x, income en y,
# además, diferenciando las distintas categorías en la variable default
# usando colour.
ggplot(Default, aes(x = balance, y = income, colour = default)) +
geom_point() + facet_wrap('student') +
theme_grey() + ggtitle("Datos Default")
set.seed(2020)
train = sample(nrow(Default),
round(nrow(Default)/2))
tail(Default[train, ])
ggplot(Default[train, ],
aes(x = balance, y = income, colour = default)) +
geom_point() + facet_wrap('student') +
theme_dark() + ggtitle("Conjunto de entrenamiento")
ggplot(Default[-train, ],
aes(x = balance, y = income, colour = default)) +
geom_point() + facet_wrap('student') +
theme_light() + ggtitle("Conjunto de prueba")
tune.rad = tune(svm, default~., data = Default[train,],
kernel = "radial",
ranges = list(
cost = c(0.1, 1, 10, 100, 1000),
gamma = seq(0.01, 10, 0.5)
)
)
;
best <- svm(default~.,  data = Default[train,],
kernel = "radial",
cost = 100,
gamma = 1.51
)
class(best)
# Matriz de confusión
mc <- table(true = Default[-train, "default"],
pred = predict(best,
newdata = Default[-train,]))
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
# Ajustar mejor el modelo
fit <- svm(default ~ ., data = Default[train,],
kernel = "radial", cost = 100, gamma = 1.51,
decision.values = TRUE)
fitted <- attributes(predict(fit, Default[-train,],
decision.values = TRUE))$decision.values
# Clasificación de las observaciones del conjunto de prueba
# utilizando valores predichos por el modelo
eti <- ifelse(fitted < 0, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
eti <- ifelse(fitted < 1.002, "Yes", "No")
mc <- table(true = Default[-train, "default"],
pred = eti)
mc
round(sum(diag(mc))/sum(colSums(mc)), 5)
rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
datos <- read.csv("datosclases.csv");
library(dplyr)
library(ggplot2)
library(e1071)
tail(datos);
dim(datos);
str(datos)
datos <- mutate(datos, y = factor(y))
ggplot(datos, aes(x = x.1, y = x.2, colour = y)) +
geom_point() +
theme_dark() + ggtitle("Datos")
train <- sample(300, 150)
tail(as.data.frame(train))
set.seed(67)
tune.out <- tune(svm, y~., data = datos[train, ],
kernel = "radial",
ranges = list(cost = c(0.1, 1, 10, 100, 1000),
gamma = c(0.5, 1, 2, 3, 4)))
# Resumen de datos
summary(tune.out)
table(true = datos[-train, "y"],
pred = predict(tune.out$best.model, newdata = datos[-train,]))
